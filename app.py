import re
import torch
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”©
MODEL_NAME = "beomi/KcELECTRA-base"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)

# ë¼ë²¨ ì •ì˜ (ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ì— ë”°ë¼ ì¡°ì • í•„ìš”)
label_map = {
    0: "ë¶€ì •",
    1: "ì¤‘ë¦½",
    2: "ê¸ì •"
}

# ê³ ê° ë°œí™”ë§Œ ì¶”ì¶œ
def extract_customer_utterances(text: str):
    pattern = r"ê³ ê°\s*:\s*(.*)"
    return re.findall(pattern, text)

# ê°ì • ì˜ˆì¸¡ í•¨ìˆ˜ (ë¼ë²¨ ê°œìˆ˜ ë™ì  ì²˜ë¦¬)
def predict_sentiment(text: str):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
    probs = F.softmax(outputs.logits, dim=1)
    label_id = torch.argmax(probs).item()
    return label_id, probs.squeeze().tolist()

# ì˜ˆì‹œ ì…ë ¥
sample_text = """
ìƒë‹´ì‚¬ : ì•ˆë…•í•˜ì„¸ìš” ê³ ê°ë‹˜. ì´ë²ˆì— ìƒˆë¡œ ì¶œì‹œëœ ë³´í—˜ ìƒí’ˆ ì•ˆë‚´ë“œë¦¬ë ¤ê³  ì „í™”ë“œë ¸ìŠµë‹ˆë‹¤.
ê³ ê° : ì•„ ë„¤, ì•ˆê·¸ë˜ë„ ë³´í—˜ì´ í•„ìš”í–ˆëŠ”ë°, ì¢‹ì€ ë‚´ìš©ì´ê² ì£ ?
ìƒë‹´ì‚¬ : ê±´ê°•ë³´í—˜ì¸ë°ìš”, ì‹¤ì†ì˜ë£Œë¹„ì™€ ì…ì›ë¹„ ë³´ì¥ì´ í¬í•¨ë˜ì–´ ìˆê³ ìš”...
ìƒë‹´ì‚¬ : ì›” ë‚©ì…ê¸ˆì€ 3ë§Œì›ì´ê³  ë³´ì¥ê¸°ê°„ì€ 10ë…„ì…ë‹ˆë‹¤.
ê³ ê° : ìŒ...ì§€ê¸ˆ ë°”ì©ë‹ˆë‹¤. ì „í™”í•˜ì§€ ë§ˆì„¸ìš”.
ê³ ê° : ì œ ì „í™”ë²ˆí˜¸ëŠ” ì–´ë–»ê²Œ ì•„ì‹ ê±°ì£ ?.
"""

# ì‹¤í–‰
customer_sentences = extract_customer_utterances(sample_text)

if not customer_sentences:
    print("ê³ ê° ë°œí™”ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    # ì²« ë¬¸ì¥ìœ¼ë¡œ í´ë˜ìŠ¤ ê°œìˆ˜ í™•ì¸ ë° ë¼ë²¨ë§µ ìƒì„±
    _, first_scores = predict_sentiment(customer_sentences[0])
    num_classes = len(first_scores)
    # ë¼ë²¨ë§µ ìë™ ìƒì„±
    label_map = {i: f"í´ë˜ìŠ¤{i}" for i in range(num_classes)}
    sentiment_counts = {label_map[i]: 0 for i in range(num_classes)}
    sentiment_scores = {label_map[i]: 0.0 for i in range(num_classes)}
    # í´ë˜ìŠ¤ë³„ ë¬¸ì¥ ì €ì¥ìš©
    class_sentences = {label_map[i]: [] for i in range(num_classes)}

    for sentence in customer_sentences:
        label_id, scores = predict_sentiment(sentence)
        if len(scores) != num_classes:
            print(f"âš ï¸ ì˜ˆì¸¡ ê²°ê³¼ í´ë˜ìŠ¤ ê°œìˆ˜({len(scores)})ê°€ {num_classes}ì´ ì•„ë‹™ë‹ˆë‹¤: {scores}")
            continue
        sentiment_counts[label_map[label_id]] += 1
        class_sentences[label_map[label_id]].append(sentence)
        for i in range(num_classes):
            sentiment_scores[label_map[i]] += scores[i]

    total = len(customer_sentences)
    avg_scores = {k: v / total for k, v in sentiment_scores.items()}
    overall_sentiment = max(avg_scores, key=avg_scores.get)
    print("ğŸ§¾ ê³ ê° ì „ì²´ ê°ì • ë¶„ì„ ê²°ê³¼\n" + "="*30)
    print(f"ì´ ë¬¸ì¥ ìˆ˜: {total}")
    print(f"ë¬¸ì¥ë³„ ê°ì • ë¶„í¬: {sentiment_counts}")
    print(f"í‰ê·  ê°ì • í™•ë¥ : {['%s: %.2f' % (k, v) for k, v in avg_scores.items()]}")
    print(f"â†’ ì „ì²´ì ìœ¼ë¡œ '{overall_sentiment}' ê°ì •ì´ ìš°ì„¸í•©ë‹ˆë‹¤.\n")

    # ê° í´ë˜ìŠ¤ë³„ë¡œ í•´ë‹¹ ë¬¸ì¥(í‚¤ì›Œë“œ) ì¶œë ¥
    print("í´ë˜ìŠ¤ë³„ ë¶„ë¥˜ëœ ë¬¸ì¥:")
    for label, sentences in class_sentences.items():
        print(f"{label} ({len(sentences)}ê°œ):")
        for s in sentences:
            print(f"  - {s}")
        print()
